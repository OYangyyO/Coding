# Week 1-2: Research framing and understanding Colour Vision Diversity (CVD). Initial literature review.

## What I Did

Over the first two weeks, I’ve been diving into the topic of Colour Vision Diversity (CVD). To be honest, it’s been pretty eye-opening! I spent a lot of time just getting familiar with the basics—like what CVD is, how it affects people, and why it’s important. CVD isn’t just about not seeing certain colours; it’s about how it impacts daily life. For example, when people with CVD try to choose food, the colours they see might not match the actual colours, which can cause confusion or even avoidant behaviour.

I also spent some time looking into how sound can help in these kinds of situations. There’s a lot of research on multisensory design, and I found a few studies that show how sound can be used to fill in gaps when visual perception isn’t reliable. My goal is to use sound as a tool to help people with CVD feel more confident in their choices.

![屏幕截图 2025-10-21 234248](https://git.arts.ac.uk/user-attachments/assets/bd8bddca-67f7-47b7-a933-0a228699d673)

## Reference Projects

While I was shaping the initial direction of my project in Week 1–2, I also revisited two reference works that became unexpectedly important in defining how I think about “multisensory perception” in the context of food and uncertainty. These weren’t just examples I read during my literature review—they genuinely shifted how I approached my own system, especially the emotional and experiential side of it.

### Eat2Pic

![image](https://git.arts.ac.uk/user-attachments/assets/4385cef1-f5b1-48ad-aa38-3bef2d438f87)

Eat2Pic stood out to me because it treats food perception as something expressive rather than functional. Instead of trying to translate taste into clear, logical data, it turns flavours into dynamic visual forms. What struck me was how unapologetically poetic it is. There is no pressure for the system to be precise or “correct.” Its whole value lies in letting people experience something familiar (taste) in a new modality (visual).

The biggest insight Eat2Pic gave me was that multisensory translation doesn’t need to be literal. It can be atmospheric, subjective, even emotional. In my early thinking, I kept assuming that if I wanted to “help” CVD users, the translation between colour and sound needed to be accurate and clear. Eat2Pic loosened that assumption. It made me realise that an experience can be meaningful even when it’s not exact—sometimes especially when it’s not exact.

It also made me think about the aesthetics of interaction. Eat2Pic feels like stepping into a soft, almost dreamlike version of sensory perception. It reminded me that my system shouldn’t feel clinical or diagnostic. If anything, I want it to feel gentle and curious, more like an invitation than a correction.

### NOISE Interactive Synthesizer

![image](https://git.arts.ac.uk/user-attachments/assets/1ceef17f-b67e-4173-abc3-1580be9e5f70)

NOISE had a very different influence. Where Eat2Pic is playful, NOISE is grounding. It uses sound not simply as output, but as a space—almost like a protective shell around the user. Watching the performance, I noticed how the sound had a way of stabilising attention. Even when visuals shifted or fragmented, the sound created a sense of presence and orientation.

This is where I first began to think about sound as emotional structure, not just information. I realised that when vision becomes unreliable (which is exactly what happens during colour confusion for CVD users), sound can provide the missing stability. It doesn’t have to reveal the “truth” of the colour; it just needs to anchor the moment.

NOISE also helped me understand the physicality of multisensory design. The installation wraps the user in a sensory field, and the performance feels embodied, not abstract. This guided my later decision to build a physical arch-shaped prototype—because I wanted the system to feel like something you step into, not something you simply look at.

## Meeting with My Supervisor

In addition to the literature review, I had a meeting with my supervisor to discuss the initial direction of my project. The discussion was extremely helpful and clarified a few important points. Here are the key takeaways:

Refining the Research Focus: My supervisor emphasized the importance of narrowing down the specific real-world applications of the project. Instead of focusing on all aspects of CVD, we decided to focus on food selection as the primary context where auditory feedback could be most useful. This is because colour misidentification is particularly problematic when it comes to choosing food (e.g., ripe fruit or food packaging).

Feasibility of Sound Mapping: We also talked about the technical aspects of sound mapping and how to choose the right sounds for different colours. My supervisor suggested starting simple—mapping just a few basic colour categories (e.g., warm vs. cool tones) to sound first, then gradually expanding.

User Testing Approach: We discussed user testing, and my supervisor advised starting with a small group of people with CVD to gather initial feedback. This will help me refine the sound mappings and ensure that the auditory feedback is both intuitive and effective.

## Achievements

Literature Review: I’ve read a few key papers on CVD, including one by Elliott (2011), which dives into the psychological effects of colour blindness. I also reviewed some studies on multisensory design and how sound could help users in decision-making processes.

Defined Project Direction: After reading up on CVD and discussing with my supervisor, I feel much clearer about my project’s goal: I want to use sound to enhance the confidence of individuals with CVD when choosing food. This will go beyond just making things clearer visually and will aim to create a more emotionally supportive environment.

Identified Research Gaps: I realized there’s a lack of solutions that help people with CVD in everyday contexts—like deciding what to eat. This was a big revelation because it confirmed that my project could bring something new to the table.

## Challenges

Limited Research on Sound for CVD: There’s plenty of research on CVD and multisensory design, but not much on using sound specifically for CVD. That made me feel like I’m really going after something new. On the flip side, it’s hard to find direct examples to base my work on.

Emotional and Perceptual Gaps: Most of the existing solutions for CVD are about correcting the visual issue (like glasses or apps), but they don’t address the emotional aspect—the feeling of uncertainty. I realized this gap in the existing research, and it’s motivated me to stick with my idea of using sound to provide emotional support.

## What I’m Thinking

Looking back at these first two weeks, I feel like I’ve gained a pretty solid foundation for where I want to take this project. I’m no longer just thinking about the technical side of CVD, but also how it affects people’s confidence and emotional well-being. Using sound could be a really cool way to help people feel more sure about the colours they’re seeing.

## Next Steps

Deepen the Literature Review: There’s still more to uncover on how sound affects perception. I’ll dive deeper into studies on auditory cues and their role in decision-making and emotional support.

Test Sound Design Concepts: I’ll start thinking about how to design the sound feedback. What kinds of sounds will work best for different colours? How do we match sound to the emotional needs of the user?

Plan User Testing: I want to set up a small-scale test where I can see if the sound feedback really helps people with CVD feel more confident about their food choices. This will give me some valuable insights for refining the system.
